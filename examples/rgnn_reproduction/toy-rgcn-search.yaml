import: [rgnn_encoder, lookup_embedder]

job.type: search
dataset.name: toy

train.optimizer.default.type: Adam
model: rgcn

search.type: grid
grid_search.parameters:
    train.optimizer.default.args.lr: [0.001, 0.0001]
    rgnn_encoder.weight_decomposition: [block, basis]
    rgnn_encoder.num_blocks_or_bases: [50, 100]
    rgnn_encoder.num_layers: [1,2]

rgcn:
  entity_embedder:
    type: lookup_embedder
    dim: 500
    initialize: xavier_uniform_
    +++: +++

  relation_embedder:
    type: lookup_embedder
    dim: 500
    initialize: xavier_uniform_
    +++: +++

  encoder:
    type: rgnn_encoder
    layer_type: torch_rgcn
    bias: True 
    weight_init: xavier_uniform_
    rel_transformation: self 
    edge_dropout: 0.5
    self_edge_dropout: 0.2
    +++: +++  
  
  decoder:
    model: distmult
    type: distmult
    scorer: DistMultScorer 

train:
  type: negative_sampling
  loss: bce
  max_epochs: 12000
  optimizer.default:
    type: Adam
    args:
      amsgrad: False
      weight_decay: 0.0

negative_sampling:
  graph_sampling: edge_neighbourhood
  graph_sampling_size: 300
  num_samples:
    s: 10
    p: 10
    o: -1  # means: as s
  filtering:
    s: True
    o: True
    p: True
    implementation: fast_if_available
  

valid:
  early_stopping: 
    patience: 30 

random_seed:
  numpy: 41504
  torch: 41504
